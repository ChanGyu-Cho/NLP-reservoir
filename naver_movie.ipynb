{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, LSTM\n",
    "\n",
    "import reservoirpy as rpy\n",
    "from reservoirpy.nodes import Reservoir, Ridge, Input, FORCE\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = tf.keras.utils.get_file(\"ratings_train.txt\",\n",
    "                        \"https://raw.github.com/ironmanciti/Infran_NLP/main/data/naver_movie/ratings_train.txt\")\n",
    "DATA_TEST_PATH = tf.keras.utils.get_file(\"ratings_test.txt\",\n",
    "                        \"https://raw.github.com/ironmanciti/Infran_NLP/main/data/naver_movie/ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_TRAIN_PATH, delimiter='\\t')\n",
    "test_data = pd.read_csv(DATA_TEST_PATH, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n",
      "(5000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터에서 50,000개의 샘플을 무작위로 선택 (재현성을 위해 random_state=1 사용)\n",
    "train_data = train_data.sample(n=50000, random_state=1)\n",
    "\n",
    "# 테스트 데이터에서 5,000개의 샘플을 무작위로 선택 (재현성을 위해 random_state=1 사용)\n",
    "test_data = test_data.sample(n=5000, random_state=1)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)\n",
    "\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence, remove_stopwords=True):\n",
    "    okt = Okt()\n",
    "    # 불용어 리스트 정의 (현재는 빈 리스트로 설정)\n",
    "    # stop_words = set(['에', '은', '는', '이', '가', '그리고', '것', '들', '수', '등', '로', '을', '를', '만', '도', '아', '의', '그', '다'])\n",
    "    stop_words = []\n",
    "\n",
    "    # 개행문자 제거\n",
    "    sentence = re.sub('\\\\\\\\n', ' ', sentence)\n",
    "\n",
    "    # 한글 외의 모든 문자 제거\n",
    "    sentence = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ ]', '', sentence)\n",
    "\n",
    "    # 형태소 분석 및 어간 추출\n",
    "    sentence = okt.morphs(sentence, stem=True)\n",
    "\n",
    "    # 불용어 제거 옵션이 True인 경우, 불용어 리스트에 포함되지 않은 토큰만 선택\n",
    "    if remove_stopwords:\n",
    "        sentence = [token for token in sentence if not token in stop_words]\n",
    "\n",
    "    # 전처리된 문장 반환\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train processed = 0\n",
      "Train processed = 10000\n",
      "Train processed = 20000\n",
      "Train processed = 30000\n",
      "Train processed = 40000\n",
      "Test processed = 0\n",
      "Test processed = 1000\n",
      "Test processed = 2000\n",
      "Test processed = 3000\n",
      "Test processed = 4000\n",
      "126.25993275642395\n"
     ]
    }
   ],
   "source": [
    "# 훈련 문장과 레이블을 저장할 리스트 초기화\n",
    "train_sentences = []\n",
    "train_labels = []\n",
    "\n",
    "# 테스트 문장과 레이블을 저장할 리스트 초기화\n",
    "test_sentences = []\n",
    "test_labels = []\n",
    "\n",
    "# 시작 시간 기록\n",
    "start = time.time()\n",
    "\n",
    "# 훈련 데이터 전처리\n",
    "for i, (sent, label) in enumerate(zip(train_data['document'], train_data['label'])):\n",
    "    # 10,000개마다 진행 상황 출력\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Train processed = {i}\")\n",
    "    # 문장 전처리 수행\n",
    "    sent = preprocessing(sent)\n",
    "    # 전처리 후 문장이 비어있지 않으면 리스트에 추가\n",
    "    if len(sent) > 0:\n",
    "        train_sentences.append(sent)\n",
    "        train_labels.append(label)\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "for i, (sent, label) in enumerate(zip(test_data['document'], test_data['label'])):\n",
    "    # 1,000개마다 진행 상황 출력\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Test processed = {i}\")\n",
    "    # 문장 전처리 수행\n",
    "    sent = preprocessing(sent)\n",
    "    # 전처리 후 문장이 비어있지 않으면 리스트에 추가\n",
    "    if len(sent) > 0:\n",
    "        test_sentences.append(sent)\n",
    "        test_labels.append(label)\n",
    "\n",
    "# 전처리에 걸린 총 시간 출력\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49571,)\n",
      "(4951,)\n",
      "[1 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 훈련 레이블을 numpy 배열로 변환\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# 테스트 레이블을 numpy 배열로 변환\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 1370, 13, 1554, 80, 520, 8870, 14637, 29, 250, 5, 3884, 16, 430, 62, 210, 30, 1612, 14, 744, 22, 229, 6, 1123, 13, 31, 43, 12, 149, 2547, 5, 741, 12, 1554, 14638, 6007, 8871, 8872, 8, 31]\n",
      "[1683, 7, 460, 1491, 106, 346, 37, 2485, 344, 760, 206, 650, 96, 270]\n"
     ]
    }
   ],
   "source": [
    "# 어휘 사전의 최대 크기 설정\n",
    "VOCAB_SIZE = 20000\n",
    "\n",
    "# Tokenizer 객체 생성 (최대 단어 수 지정 및 OOV(Out-Of-Vocabulary) 토큰 설정)\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "\n",
    "# 훈련 문장에 대해 토크나이저 학습 수행 (단어 인덱스 구축)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "# 훈련 문장들을 시퀀스로 변환\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "\n",
    "# 테스트 문장들을 시퀀스로 변환\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "# 첫 번째 시퀀스 출력\n",
    "print(train_sequences[0])\n",
    "print(test_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49571, 15)\n",
      "(4951, 15)\n",
      "[   90  1370    13  1554    80   520  8870 14637    29   250     5  3884\n",
      "    16   430    62]\n",
      "[1683    7  460 1491  106  346   37 2485  344  760  206  650   96  270\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "max_length = 15\n",
    "\n",
    "# 훈련 시퀀스를 패딩 처리 (최대 길이를 15로 설정, 'post' 방식으로 잘라내고 패딩)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# 테스트 시퀀스를 패딩 처리 (최대 길이를 15로 설정, 'post' 방식으로 잘라내고 패딩)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "print(train_padded.shape)\n",
    "print(test_padded.shape)\n",
    "\n",
    "# 첫 번째 패딩된 시퀀스 출력\n",
    "print(train_padded[0])\n",
    "print(test_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 최적화를 통해 지정한 하이퍼파라미터들\n",
    "# n-flod 방식이 아니기에, test 데이터에 과적합 되었을 수 있음\n",
    "reservoir = Reservoir(200, sr=0.74, lr=0.9)  # 유닛 갯수 등 여러 하이퍼파라미터 지정\n",
    "readout = Ridge(output_dim=1, ridge=0)  # 읽기 아웃 계층\n",
    "\n",
    "reservoir <<= readout\n",
    "\n",
    "# 모델 파이프라인 구성\n",
    "esn = Input(input_dim=train_padded.shape[1]) >> reservoir >> readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-5: 49571it [00:03, 12944.22it/s], ?it/s]\n",
      "Running Model-5: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node Ridge-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-5: 49571it [00:03, 14783.99it/s]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 53.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습 파라미터 설정\n",
    "epochs = 1 # 에포크 수\n",
    "\n",
    "# 학습 과정 (배치 처리)\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    # 모델 학습\n",
    "    # teachers forcing 사용\n",
    "    esn=esn.fit(train_padded, train_labels.reshape(-1,1), force_teachers=True)\n",
    "\n",
    "# train 데이터에 대한 평가\n",
    "train_predictions_run = esn.run(train_padded)\n",
    "predictions_int =[1 if y_p[0] >= 0.5 else 0 for y_p in train_predictions_run]  # 연속적인 출력을 0 또는 1로 이진화\n",
    "accuracy = accuracy_score(train_labels, predictions_int)\n",
    "print(f\"정확도: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-5: 4951it [00:00, 13351.73it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 51.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "# stateful=False를 통해 test 데이터로 상태를 변화시키지 않음\n",
    "predictions = esn.run(test_padded, stateful=True)\n",
    "predictions_int =[1 if y_p[0] >= 0.5 else 0 for y_p in predictions]  # 연속적인 출력을 0 또는 1로 이진화\n",
    "\n",
    "# 성능 평가\n",
    "accuracy = accuracy_score(test_labels, predictions_int)\n",
    "print(f\"정확도: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오랜', '만', '에', '접', '한', '수작']\n",
      "[[349, 26, 7, 480, 22, 378]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-7: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4791695]]\n",
      "New Sentence: ['오랜', '만', '에', '접', '한', '수작']\n",
      "Predicted Sentiment: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 새로운 문장\n",
    "new_sentence = \"오랜만에 접한 수작\"\n",
    "\n",
    "new_sentence = preprocessing(new_sentence)\n",
    "print(new_sentence)\n",
    "\n",
    "# 새로운 문장을 토큰화\n",
    "new_sequence = tokenizer.texts_to_sequences([new_sentence])\n",
    "print(new_sequence)\n",
    "\n",
    "# 패딩 적용\n",
    "new_padded = pad_sequences(new_sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Reservoir 모델을 통해 상태 계산\n",
    "predict = esn.run(new_padded, stateful=False)\n",
    "print(predict)\n",
    "\n",
    "# Ridge 모델을 통해 예측값 생성\n",
    "prediction_int =1 if predict >= 0.5 else 0  # 연속적인 출력을 0 또는 1로 이진화\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"New Sentence: {new_sentence}\")\n",
    "print(f\"Predicted Sentiment: {'Positive' if prediction_int == 1 else 'Negative'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
