{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# TSV 파일 읽기\n",
    "with open(\"review.sorted.uniq.preprocessing.tok.bpe.tsv\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 데이터를 저장할 리스트 초기화\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 각 줄을 처리\n",
    "for line in lines:\n",
    "    # 탭(\\t)으로 구분\n",
    "    split_line = line.strip().split('\\t')\n",
    "    \n",
    "    # 첫 번째 열: 레이블 처리\n",
    "    if split_line[0].lower() == 'positive':\n",
    "        labels.append(1)\n",
    "    elif split_line[0].lower() == 'negative':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown label: {split_line[0]}\")\n",
    "    data.append(split_line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 수: 150000\n",
      "단어수: 24630\n",
      "다 녹 아서 왓 어요 . 짜증\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.5 GiB for an array with shape (150000, 24630) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_mini[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# features 객체를 NumPy 배열로 변환\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m vectorized_sentences \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1106\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1106\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\qqppq\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:1327\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 27.5 GiB for an array with shape (150000, 24630) and data type int64"
     ]
    }
   ],
   "source": [
    "## 리뷰 벡터화\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer 객체 생성\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# sentences 데이터에 대한 피처 변환 수행\n",
    "# sentences는 분석할 텍스트 데이터의 리스트\n",
    "\n",
    "# neg는 앞에, pos는 뒤에 있기에 이를 합침\n",
    "# 30만개는 너무 커서 한번에 안담긴다...\n",
    "bag_size_t = 150000\n",
    "bag_size = int(bag_size_t/2)\n",
    "data_mini = data[:bag_size]+data[-bag_size:]\n",
    "labels_mini = labels[:bag_size] +labels[-bag_size:]\n",
    "features = count_vectorizer.fit_transform(data_mini)\n",
    "print(f\"document 수: {features.shape[0]}\")\n",
    "print(f\"단어수: {features.shape[1]}\")\n",
    "\n",
    "# features 객체를 NumPy 배열로 변환\n",
    "vectorized_sentences = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "# 벡터화된 문장과 피처 이름을 이용해 DataFrame 생성\n",
    "df = pd.DataFrame(vectorized_sentences, columns=feature_names)\n",
    "\n",
    "# 데이터프레임의 인덱스 이름 지정\n",
    "df.index.name = 'sentence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 문장으로 부터 상위 100 개 단어로 vocabulary 작성\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "# sentences에 포함된 문장들을 기반으로 단어의 토큰화를\n",
    "# 수행하며, 각 단어에 고유한 인덱스를 할당\n",
    "tokenizer.fit_on_texts(data_mini)\n",
    "\n",
    "# sentences 데이터를 시퀀스로 변환\n",
    "sequences = tokenizer.texts_to_sequences(data_mini)\n",
    "\n",
    "# 시퀀스에 패딩 적용 (문장의 뒤쪽을 패딩하고, 필요시 뒤쪽을 잘라냄)\n",
    "padded = pad_sequences(sequences, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reservoirpy as rpy\n",
    "from reservoirpy.nodes import Reservoir\n",
    "from reservoirpy.nodes import Reservoir, Ridge, Input\n",
    "import numpy as np\n",
    "\n",
    "ran = 50000\n",
    "# 단순한 +이어붙이기는 오류가 발생한다, padded는 2차원이기 때문이다\n",
    "X_train = np.concatenate([padded[:ran], padded[-ran:]], axis=0)\n",
    "Y_train = labels_mini[:ran] + labels_mini[-ran:]\n",
    "X_test = np.concatenate([padded[ran+1:ran+500], padded[-ran-500:-ran-1]], axis=0)\n",
    "Y_test = labels_mini[ran+1:ran+500] + labels_mini[-ran-500:-ran-1]\n",
    "\n",
    "source = Input()\n",
    "reservoir = Reservoir(500, sr=0.9, lr=0.1)\n",
    "readout = Ridge( ridge=1e-6)\n",
    "\n",
    "model = source >> reservoir >> readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "states_train = []\n",
    "for x in X_train:\n",
    "    states = reservoir.run(x, reset=True)\n",
    "    states_train.append(states[-1, np.newaxis])\n",
    "    clear_output(wait=True)  # 출력 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ridge-0': Ridge(ridge=1e-06, input_bias=True, in=500, out=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readout.fit(states_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-0: 100%|██████████| 1/1 [00:00<00:00, 982.04it/s]\n",
      "Running Ridge-0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = []\n",
    "for x in X_test:\n",
    "    states = reservoir.run(x, reset=True)\n",
    "    y = readout.run(states[-1, np.newaxis])\n",
    "    Y_pred.append(y)\n",
    "    clear_output(wait=True)  # 출력 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  76.854 %\n",
      "0.7685370741482966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "Y_pred_class = [1 if y_p[0] >= threshold else 0 for y_p in Y_pred]\n",
    "Y_test_class = [y_t for y_t in Y_test]\n",
    "\n",
    "score = accuracy_score(Y_test_class, Y_pred_class)\n",
    "\n",
    "print(\"Accuracy: \", f\"{score * 100:.3f} %\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.66268846]]), array([[0.64046051]]), array([[0.60275193]]), array([[0.62892907]]), array([[0.62892907]]), array([[0.66268846]]), array([[0.60275193]]), array([[0.66268846]]), array([[0.64046051]]), array([[0.64046051]])]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred[-10:])\n",
    "print(Y_test[-10:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단일 문장 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-0: 100%|██████████| 1/1 [00:00<00:00, 992.97it/s]\n",
      "Running Ridge-0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sentence: 좋아!\n",
      "Predicted Sentiment: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 새로운 문장\n",
    "new_sentence = \"좋아!\"\n",
    "\n",
    "# 새로운 문장을 토큰화\n",
    "new_sequence = tokenizer.texts_to_sequences([new_sentence])\n",
    "\n",
    "# 패딩 적용\n",
    "new_padded = pad_sequences(new_sequence, maxlen=padded.shape[1], padding='post', truncating='post')\n",
    "\n",
    "# Reservoir 모델을 통해 상태 계산\n",
    "new_state = reservoir.run(new_padded, reset=True)\n",
    "\n",
    "# Ridge 모델을 통해 예측값 생성\n",
    "new_pred = readout.run(new_state[-1, np.newaxis])\n",
    "\n",
    "# 예측값을 클래스(긍정/부정)로 변환\n",
    "predicted_class = 1 if new_pred[0][0] >= threshold else 0\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"New Sentence: {new_sentence}\")\n",
    "print(f\"Predicted Sentiment: {'Positive' if predicted_class == 1 else 'Negative'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
